# House Prices - Advanced Regression Techniques

본 프로젝트는 Ames 주택의 가격을 예측하는 회귀 모델을 구축한 과정입니다.

---

## 프로젝트 개요

| 항목         | 내용                                                                 |
|--------------|----------------------------------------------------------------------|
| 목표         | Ames 주택 데이터 기반의 `SalePrice` 예측                             |
| 주요 기법     | 로그 변환, 이상치 제거, One-Hot 인코딩, 모델 앙상블                    |
| 사용 모델     | XGBoost, LightGBM, Lasso, Ridge                                       |
| 평가 지표     | RMSE, MAE, RMSLE                                                     |
| 최종 제출물   | `submission.csv` (앙상블 결과 역변환하여 제출)                        |

---

## 데이터 전처리

| 항목              | 처리 방식                                                                 |
|-------------------|--------------------------------------------------------------------------|
| 로그 변환          | `SalePrice`, `GrLivArea`, `1stFlrSF`, `2ndFlrSF`, `TotalBsmtSF`에 `log1p` 적용 |
| 결측치 처리        | - `PoolQC`, `MiscFeature`: 'NoPool', 'NoMisc' 대체<br>- `LotFrontage`: `Neighborhood` 기준 중앙값 대체<br>- `Garage*`, `Bsmt*` 등 도메인 기반 치환 |
| 범주형 인코딩      | `get_dummies()`로 One-Hot Encoding 적용                                 |
| 이상치 제거        | - `GrLivArea > 4000 & SalePrice < 300000`<br>- `GarageArea` IQR 초과값 제거 |

---

## 사용한 회귀 모델

| 모델 종류       | 설명                                               |
|----------------|----------------------------------------------------|
| XGBoost        | 결정 트리 기반 Gradient Boosting 모델               |
| LightGBM       | 경량화된 Boosting 모델, 빠른 학습 속도              |
| Lasso          | L1 규제 적용, 피처 선택 기능                        |
| Ridge          | L2 규제 적용, 과적합 방지                          |
| 앙상블 전략     | `XGBoost(40%) + Lasso(30%) + Ridge(30%)` 조합 사용 |

---

## 성능 평가

| 평가 지표      | 설명                                                   |
|----------------|--------------------------------------------------------|
| RMSE           | 평균 제곱 오차의 제곱근                                 |
| MAE            | 절대 오차 평균                                          |
| RMSLE          | 로그 스케일에서의 평균 제곱근 오차                      |
| 캐글 기준 점수 | `submission.csv`는 `np.expm1()`로 역변환 후 제출됨        |

---

## 회고 및 개선 포인트

| 항목                  | 내용                                                                 |
|-----------------------|----------------------------------------------------------------------|
| 전처리 전략의 교훈     | 처음부터 과도한 전처리보다는, **기본 전처리 → 모델 평가 → 개선 반복** 방식이 효과적임 |
| 오차 원인 분석         | 고가 주택의 예측력이 낮았고, 이는 고급 주택 특성을 반영하는 피처 제거 때문이었음       |
| 개선 조치             | `PoolQC`, `MiscFeature` 복구 및 보존 → 예측 성능 개선에 기여                      |

---

## 학습 요약

| 배운 점                                                                 |
|--------------------------------------------------------------------------|
| 데이터 전처리는 "많이"보다 "의미 있게" 수행해야 함                         |
| 반복 실험을 통해 모델과 전처리의 적정 조합을 찾아야 함                    |
| 희귀하거나 특이한 피처도 예측에 있어 중요한 정보가 될 수 있음              |

